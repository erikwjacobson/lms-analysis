{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "\n",
    "The data is contained in multiple data files, which have to follow a number of assumptions that were enforced before running this script:\n",
    "\n",
    "* All datasets are in csv files and cleaned for correct column data.\n",
    "    * CSV had some errors beforehand, causing data to be offset as a result of commas in specific columns.\n",
    "* Each term has a LMS usage file with the filename format `term_lms_usage.csv`.\n",
    "* Course success data is contained in a single csv with a filename format `course_success.csv`.\n",
    "\n",
    "Data loading consists of three parts:\n",
    "   \n",
    "1. Loading each LMS dataset and generating columns which will be used for mapping later.\n",
    "2. Combining all LMS usage data into one giant dataset of all courses from 2016-2019.\n",
    "3. Mapping the LMS usage data to the course success data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Unique Identification Columns for LMS Data\n",
    "\n",
    "There's a few types of columns that need to be generated:\n",
    "* Pieces of the OrgUnitCode, which contains information about term, course id, and whether the course is merged.\n",
    "* Pieces of the OrgUnitName, which contains course number(s), section number(s), name, and sometimes department code. This is done in a later step.\n",
    "    \n",
    "### OrgUnitCode\n",
    "\n",
    "There are two cases for the OrgUnitCode\n",
    "* When there's 11 digits followed by a letter \"M\", denoting merged.\n",
    "    * Matched using regex `^\\d{11}M$`.\n",
    "* When there's just 11 digits.\n",
    "    * Matched using regex `^\\d{11}$`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Generates columns based on unit code data\n",
    "# \n",
    "# @param df - LMS data Pandas DataFrame\n",
    "#\n",
    "def generate_unit_columns(df):\n",
    "    ## OrgUnitCode Column\n",
    "    # Handle Unmerged Case\n",
    "    is_not_merged = df['OrgUnitCode'].astype(str).str.match('^\\d{11}$') == True\n",
    "    # Handle Merged Case\n",
    "    is_merged = df['OrgUnitCode'].astype(str).str.match('^\\d{11}M$') == True\n",
    "    \n",
    "    # Remove values that don't match the following:\n",
    "    # * 11 digit number\n",
    "    # * 11 digit number followed by \"M\"\n",
    "    df = df.loc[(is_merged | is_not_merged)]\n",
    "    \n",
    "    # Specify that the data is not merged\n",
    "    df.loc[is_not_merged, 'Merged'] = False\n",
    "    \n",
    "    # Specify that the data is merged\n",
    "    df.loc[is_merged, 'Merged'] = True\n",
    "    \n",
    "    # Generate term column\n",
    "    df.loc[:,'CourseTerm'] = df['OrgUnitCode'].str[:5]\n",
    "    \n",
    "    # Generate course ID column\n",
    "    df.loc[:,'CourseID'] = df['OrgUnitCode'].str[5:11]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Unit Columns for Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20161 : (589, 55)\n",
      "20163 : (1971, 55)\n",
      "20165 : (1859, 56)\n",
      "20171 : (577, 55)\n",
      "20173 : (2127, 58)\n",
      "20175 : (1883, 55)\n",
      "20181 : (555, 55)\n",
      "20183 : (2008, 57)\n",
      "20185 : (1819, 57)\n",
      "20191 : (583, 57)\n",
      "20193 : (1918, 57)\n",
      "loaded all lms data\n"
     ]
    }
   ],
   "source": [
    "# Load the individual term LMS data\n",
    "terms = [\n",
    "    '20161', # 2015 Summer\n",
    "    '20163', # 2015 Fall\n",
    "    '20165', # 2016 Spring\n",
    "    '20171', # 2016 Summer\n",
    "    '20173', # 2016 Fall\n",
    "    '20175', # 2017 Spring\n",
    "    '20181', # 2017 Summer\n",
    "    '20183', # 2017 Fall \n",
    "    '20185', # 2018 Spring\n",
    "    '20191', # 2018 Summer\n",
    "    '20193', # 2018 Fall\n",
    "#     '20195', # 2019 Spring (this is not working right now as a result of the format)\n",
    "]\n",
    "lms_usage = {}\n",
    "for term in terms:\n",
    "    df = pd.read_csv('{}_lms_usage.csv'.format(term))\n",
    "    lms_usage[term] = generate_unit_columns(df)\n",
    "    print('{} : {}'.format(term, lms_usage[term].shape))\n",
    "print('loaded all lms data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all of the LMS Data Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15889, 61)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lms_usage = pd.concat(list(lms_usage.values()), sort=False, ignore_index=True)\n",
    "all_lms_usage.to_csv('all_lms_usage_combined.csv')\n",
    "all_lms_usage.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Percentage of Matched Courses with Regular Expressions\n",
    "\n",
    "* As mentioned earlier, course data has to be extracted from a column that contains information in a variety of formats. The column contains information such as a name, department identified, course ID number, and section numbers. Since all of this is coming from the title of the course, which is unstandardized in the LMS, this data is often ordered in different ways for different courses.\n",
    "    * For example, one course might be `MATH 100-04 College Algebra`, and another course might has a name `College Algebra MATH 100/4`. Both course titles contain the same information, just in different formats.\n",
    "\n",
    "* The following scripts are used to verify that most of the data is being captured by the formats that I've specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unmerged:  12603\n",
      "Total for match ^([A-Za-z&/: ]{5,}) (\\d{3}W?)[ -/](\\d{2})$: 442\n",
      "Total for match ^([A-Z]{3,4}) (\\d{3}W?)[ -/](\\d{2}) ([A-Za-z&/: ]{5,})$: 10104\n",
      "Total Matched: 10546\n",
      "Percent Matched: 10546 / 12603 = 83.6784892485916%\n"
     ]
    }
   ],
   "source": [
    "## Unmerged\n",
    "unmerged = all_lms_usage[all_lms_usage['Merged'] == False]\n",
    "total_unmerged = unmerged.shape[0]\n",
    "\n",
    "print('Total Unmerged: ', total_unmerged)\n",
    "total_matched = 0\n",
    "regex = [\n",
    "    '^([A-Za-z&/: ]{5,}) (\\d{3}W?)[ -/](\\d{2})$',\n",
    "    '^([A-Z]{3,4}) (\\d{3}W?)[ -/](\\d{2}) ([A-Za-z&/: ]{5,})$'\n",
    "]\n",
    "for match in regex:\n",
    "    match_count = unmerged[unmerged['OrgUnitName'].astype(str).str.match(match) == True].shape[0]\n",
    "    print('Total for match {}: {}'.format(match, match_count))\n",
    "    total_matched += match_count\n",
    "print('Total Matched: {}'.format(total_matched))\n",
    "print('Percent Matched: {} / {} = {}%'.format(total_matched,total_unmerged, (total_matched / total_unmerged * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total merged:  3286\n",
      "Total for match ^([A-Z]{3,4}) ((\\d{3}W?)([ -/](\\d{3}W?)){0,5})[ -/]?((\\d{2})([ -/](\\d{2})){0,5}) ([A-Za-z&/: ]{5,})$: 2091\n",
      "Total for match ^([A-Za-z&/: ]{5,}) ((\\d{3}W?)([ -/](\\d{3}W?)){0,5})[ -/]?((\\d{2})([ -/](\\d{2})){0,5})$: 188\n",
      "Total Matched: 2279\n",
      "Percent Matched: 2279 / 3286 = 69.35483870967742%\n"
     ]
    }
   ],
   "source": [
    "## Merged\n",
    "merged = all_lms_usage[all_lms_usage['Merged'] == True]\n",
    "total_merged = merged.shape[0]\n",
    "\n",
    "print('Total merged: ', total_merged)\n",
    "total_matched = 0\n",
    "regex = [\n",
    "    '^([A-Z]{3,4}) ((\\d{3}W?)([ -/](\\d{3}W?)){0,5})[ -/]?((\\d{2})([ -/](\\d{2})){0,5}) ([A-Za-z&/: ]{5,})$',\n",
    "    '^([A-Za-z&/: ]{5,}) ((\\d{3}W?)([ -/](\\d{3}W?)){0,5})[ -/]?((\\d{2})([ -/](\\d{2})){0,5})$'\n",
    "]\n",
    "for match in regex:\n",
    "    match_count = merged[merged['OrgUnitName'].astype(str).str.match(match) == True].shape[0]\n",
    "    print('Total for match {}: {}'.format(match, match_count))\n",
    "    total_matched += match_count\n",
    "print('Total Matched: {}'.format(total_matched))\n",
    "print('Percent Matched: {} / {} = {}%'.format(total_matched,total_merged, (total_matched / total_merged * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It's a lot more difficult to capture all types of merged courses, since they consist of multiple classes combined, and how those classes are combined (i.e. multiple sections, classes across departments, multiple different classes in the same department, etc.) varies so widely across the LMS. ~70% was sufficient to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Capture Groups\n",
    "\n",
    "* Once the data was verified to consist of multiple formats, I could use regular expressions to extract that information and put it into new columns. This was necessary since this data had to be merged with a dataset from a different source (student success data) which didn't contain any links to the LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unmerged TODO\n",
    "unmerged = all_lms_usage[all_lms_usage['Merged'] == False]\n",
    "total_matched = 0\n",
    "regex = [\n",
    "    '^(?P<name>[A-Za-z&/: ]{5,}) (?P<number>\\d{3}W?)[ -/](?P<sections>\\d{2})$',\n",
    "    '^(?P<code>[A-Z]{3,4}) (?P<number>\\d{3}W?)[ -/](?P<sections>\\d{2}) (?P<name>[A-Za-z&/: ]{5,})$'\n",
    "]\n",
    "final_unmerged_columns = pd.DataFrame(columns=['code','number','sections', 'name'])\n",
    "for match in regex:\n",
    "    matched = unmerged[unmerged['OrgUnitName'].astype(str).str.match(match) == True]\n",
    "    new_columns = matched['OrgUnitName'].astype(str).str.extract(match)\n",
    "    if('code' not in new_columns.columns):\n",
    "        columns=['number','sections','name']\n",
    "    else:\n",
    "        columns=['code','number','sections', 'name']\n",
    "    final_unmerged_columns = final_unmerged_columns.append(new_columns[columns], ignore_index=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Merged\n",
    "merged = all_lms_usage[all_lms_usage['Merged'] == True]\n",
    "regex = [\n",
    "    ## DepartmentCode First\n",
    "    # Multiple Course Multiple Section\n",
    "    # e.g. PSYC 123/234 01 Name\n",
    "    '^(?P<code>[A-Z]{3,4}) (?P<number>(\\d{3}W?)([ -/](\\d{3}W?)){0,5})[ -/]?(?P<sections>(\\d{2})([ -/](\\d{2})){0,5}) (?P<name>[A-Za-z&/: ]{5,})$',\n",
    "\n",
    "    ## Name First\n",
    "    # One Course Multiple Sections\n",
    "    # e.g. Intro to Psychology 450/550 01/02/03\n",
    "    '^(?P<name>[A-Za-z&/: ]{5,}) (?P<number>(\\d{3}W?)([ -/](\\d{3}W?)){0,5})[ -/]?(?P<sections>(\\d{2})([ -/](\\d{2})){0,5})$'\n",
    "]\n",
    "final_merged_columns = pd.DataFrame(columns=['code','number','sections', 'name'])\n",
    "for match in regex:\n",
    "    matched = merged[merged['OrgUnitName'].astype(str).str.match(match) == True]\n",
    "    new_columns = matched['OrgUnitName'].astype(str).str.extract(match)\n",
    "    if('name' not in new_columns.columns):\n",
    "        columns=['code','number','sections']\n",
    "    elif('code' not in new_columns.columns):\n",
    "        columns=['number','sections','name']\n",
    "    else:\n",
    "        columns=['code','number','sections', 'name']\n",
    "    final_merged_columns = final_merged_columns.append(new_columns[columns], ignore_index=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined new extracted columns\n"
     ]
    }
   ],
   "source": [
    "final_columns = final_merged_columns.append(final_unmerged_columns, ignore_index=False)\n",
    "all_lms_usage = all_lms_usage.join(final_columns, how='left')\n",
    "print('Joined new extracted columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining a Set of Usable Courses\n",
    "\n",
    "* Once all of this identifying data had been moved into separate columns, only the ones which contained all of the information were kept, and the remainder were dropped. This created a usable set of courses that could be combined with the success data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12825, 65)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_lms_data = all_lms_usage.dropna(subset=['code','number','sections','name'], how='all')\n",
    "usable_lms_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_lms_data.to_csv('usable_lms_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total of 80% of courses were usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8071621876770092"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_lms_data.shape[0] / all_lms_usage.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the LMS Usage Data with the Success Data\n",
    "\n",
    "* Now that all of the identifying information had been extracted, the LMS usage data could be merged with the student success data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the enrollment and success data\n",
    "enrollment = pd.read_csv('course_success.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding necessary columns to enrollment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course Code (e.g. MATH)\n",
    "enrollment['CourseCode'] = enrollment['Course'].astype(str).str.split(' ').apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging \"Unmerged\" Courses\n",
    "\n",
    "* This is the easy part, since unmerged courses map one-to-one with the success rate records, so I can just match columns together between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting just unmerged data from the usable courses dataset\n",
    "uld_unmerged = usable_lms_data[usable_lms_data['Merged'] == False]\n",
    "\n",
    "# Ensuring the code I will be comparing is an integer for the sake of \n",
    "uld_unmerged.loc[:,'OrgUnitCode'] = uld_unmerged['OrgUnitCode'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating OrgUnitCode\n",
    "\n",
    "* The LMS usage data has information compiled into an OrgUnitCode, which we extracted in earlier steps. Now we want to construct this in the enrollment or student success dataset so we can match them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment['OrgUnitCode'] = (enrollment['YRTR'].astype(str) + # Year term (e.g. 20161)\n",
    "                             enrollment['COU_ID'].astype(str).apply(lambda x: (6 - len(x)) * '0') + # fill with 0s \n",
    "                             enrollment['COU_ID'].astype(str)) # Course Number (e.g. 45)\n",
    "enrollment['OrgUnitCode'] = enrollment['OrgUnitCode'].astype('int64') # forcing tnteger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the LMS usage dataset, and looking only at the unmerged courses, we can filter by those which exist in the enrollment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmerged_filtered = uld_unmerged[uld_unmerged['OrgUnitCode'].isin(enrollment['OrgUnitCode'].tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can merge these two datasets together using this column OrgUnitCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_unmerged = unmerged_filtered.merge(enrollment, on='OrgUnitCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final unmerged combined with enrollment data\n",
    "combined_unmerged.to_csv('combined_unmerged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging \"Merged\" Courses\n",
    "\n",
    "* In the enrollment dataset, the courses are all listed individually, whereas in the LMS dataset, some courses consist of multiple different courses combined. For each of the \"merged\" courses in the LMS dataset, corresponding enrollment data has to be merged together and then connected together to tie success data with LMS usage.\n",
    "\n",
    "#### Process\n",
    "\n",
    "* For each of the individual merged courses:\n",
    "\n",
    "    * Determine which pattern the course falls into\n",
    "        * Multiple sections\n",
    "        * Multiple courses (grad + undergrad)\n",
    "        * Multiple departments\n",
    "        * Multiple courses and sections\n",
    "        \n",
    "    * Select courses that were merged in one LMS course\n",
    "        * Match year term, section number, department, and code\n",
    "    \n",
    "    * Combine data \n",
    "    \n",
    "    * Append column of combined data to row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the merged courses\n",
    "uld_merged = usable_lms_data[usable_lms_data['Merged'] == True]\n",
    "\n",
    "# Establish columns that are needed\n",
    "uld_merged_columns = uld_merged[['OrgUnitCode', 'DeptName','code','name','number','sections', 'CourseTerm']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Merge Loop\n",
    "\n",
    "* For each individual row in the LMS courses dataset of merged courses,\n",
    "    * Establish the enrollment records that have the same term, department, course numbers, and sections.\n",
    "    * Merge the needed data together\n",
    "        * Total students and total successful students\n",
    "    * Gather necessary data consistent across all courses\n",
    "        * Instruction method, course group, and assignment type\n",
    "    * Establish a new dataframe to append to the final, merged set of data\n",
    "    \n",
    "    \n",
    "A caveat:\n",
    "* This is pretty inefficient, but I couldn't think of a better way to do this given the project deadlines. I'm sure there are some other iterative functions or unique ways of getting this accomplished, but I used the tools I knew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns=['index','Count','Successful', 'Course Group','Instruction Method', 'Assignment Type'])\n",
    "\n",
    "for key,item in uld_merged_columns.iterrows():\n",
    "    same_term = (enrollment['YRTR'].astype(int) == int(item['CourseTerm']))\n",
    "    same_department = (enrollment['Department'] == item['DeptName'])\n",
    "    same_numbers = (enrollment['COU_NBR'].isin(item['number'].split('/')))\n",
    "    same_sections = (enrollment['Section'].isin(item['sections'].split('/')))\n",
    "    temp = enrollment[same_numbers & same_term & same_department & same_sections]\n",
    "    \n",
    "    if(not temp.empty == True):\n",
    "        count = temp['Count'].sum()\n",
    "        successful = temp['Successful'].sum()\n",
    "        course_group = list(temp['Course Group'].values)\n",
    "        if(len(set(course_group))==1):\n",
    "            course_group = list(temp['Course Group'].values)[0]\n",
    "        instruction_method = list(temp['Instruction Method'].values)[0]\n",
    "        assignment_type = list(temp['Assignment Type'].values)[0]\n",
    "        \n",
    "        new_df = pd.DataFrame({'index': [key], \n",
    "                               'Count': [count], \n",
    "                               'Successful': [successful], \n",
    "                               'Course Group': [course_group],\n",
    "                               'Instruction Method': [instruction_method],\n",
    "                               'Assignment Type': [assignment_type]\n",
    "                              })\n",
    "        final_df = final_df.append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the index is set for the final dataframe\n",
    "final_df = final_df.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the merged data with its corresponding enrollment data\n",
    "uld_merged_final = uld_merged.join(final_df, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalize into a CSV \n",
    "uld_merged_final.to_csv('combined_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data Processing\n",
    "\n",
    "Some last minute steps are needed to have a nice, clean dataset with all of the columns we need to run the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one big file with all merged and unmerged courses\n",
    "merged = pd.read_csv('combined_merged.csv')\n",
    "unmerged = pd.read_csv('combined_unmerged.csv')\n",
    "all_courses = merged.append(unmerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only need the following columns for analysis\n",
    "columns = ([\n",
    "    'OrgUnitName',\n",
    "    'DeptName',\n",
    "    'EnrollmentCount',\n",
    "    'StudentCount',\n",
    "    'FacultyCount',\n",
    "    'ContentModuleCount',\n",
    "    'ContentTopicCount (DraftsNotIncluded)',\n",
    "    'DropBoxCount',\n",
    "    'DropboxSubmissionFileCount',\n",
    "    'DiscussionTopicCount',\n",
    "    'DiscussionTopicPostCount',\n",
    "    'QuizCount',\n",
    "    'SurveyCount',\n",
    "    'SelfAssessments',\n",
    "    'NewsCount',\n",
    "    'GradeItemCount_Excluding_FinalCalc_FinalAdj_GradeCategories',\n",
    "    'CompetencyCount',\n",
    "    'LearningObjectiveCount',\n",
    "    'RubricCount',\n",
    "    'LtiLinkCount',\n",
    "    'CourseTerm',\n",
    "    'Course Group',\n",
    "    'Instruction Method',\n",
    "    'Assignment Type',\n",
    "    'Successful',\n",
    "    'Count',\n",
    "    'Merged'\n",
    "])\n",
    "\n",
    "analysis_dataset = all_courses[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Columns for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns for ease of typing\n",
    "analysis_dataset.loc[:,'GradeItemCount'] = analysis_dataset['GradeItemCount_Excluding_FinalCalc_FinalAdj_GradeCategories']\n",
    "analysis_dataset.loc[:,'ContentTopicCount'] = analysis_dataset['ContentTopicCount (DraftsNotIncluded)']\n",
    "\n",
    "# Creating the success_rate outcome variable (outcome variable for this analysis)\n",
    "analysis_dataset.loc[:,'Success_Rate'] = analysis_dataset['Successful'] / analysis_dataset['Count'] \n",
    "\n",
    "# Establishing that records which aren't just in one of the course groups are mixed\n",
    "#  - Previous methods of merging made it so that the whole array of course groups were just \n",
    "#    stringified and placed into the column, so any that weren't explicitly one of these\n",
    "#    groups were considered mixed type.\n",
    "analysis_dataset.loc[:,'CourseGroupFixed'] = analysis_dataset['Course Group']\n",
    "analysis_dataset.loc[~analysis_dataset['Course Group'].isin(['UG Lower','UG Upper','Graduate','Doctoral']), \n",
    "                    'CourseGroupFixed'] = 'Mixed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 10528 courses were analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10528, 31)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_dataset.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
